"""This module binds low-level API classes for all Mesoscope-VR components (cameras, microcontrollers, Zaber motors).
These bindings streamline the API used to interface with these components during experiment and training runtimes."""

from pathlib import Path

import numpy as np
from ataraxis_time import PrecisionTimer
from ataraxis_video_system import (
    VideoCodecs,
    VideoSystem,
    VideoFormats,
    CameraBackends,
    GPUEncoderPresets,
    InputPixelFormats,
    OutputPixelFormats,
)
from ataraxis_base_utilities import LogLevel, console
from ataraxis_data_structures import DataLogger
from ataraxis_time.time_helpers import convert_time
from ataraxis_communication_interface import MicroControllerInterface

from tools import get_system_configuration
from sl_experiment.shared_components import (
    LickInterface,
    ValveInterface,
)
class MicroControllerInterfaces:
    """Interfaces with all Ataraxis Micro Controller (AMC) devices that control Mesoscope-VR system hardware and acquire
    non-video behavior data.

    This class interfaces with the three AMC controllers used during various runtimes: Actor, Sensor, and Encoder. The
    class exposes methods to send commands to the hardware modules managed by these microcontrollers. In turn, these
    modules control specific components of the Mesoscope-Vr system, such as rotary encoders, solenoid valves, and
    conductive lick sensors.

    Notes:
        This class is primarily intended to be used internally by the _MesoscopeExperiment and _BehaviorTraining
        classes. Our maintenance CLI (sl-maintain) is the only exception to this rule, as it directly uses this class to
        facilitate Mesoscope-VR maintenance tasks.

        Calling the initializer does not start the underlying processes. Use the start() method before issuing other
        commands to properly initialize all remote processes. This design is intentional and is used during experiment
        and training runtimes to parallelize data preprocessing for the previous session and runtime preparation for the
        following session.

    Args:
        data_logger: The initialized DataLogger instance used to log the data generated by the managed microcontrollers.
            For most runtimes, this argument is resolved by the _MesoscopeExperiment or _BehaviorTraining classes that
            initialize this class.

    Attributes:
        _started: Tracks whether the VR system and experiment runtime are currently running.
        _system_configuration: Stores the configuration parameters used by the Mesoscope-VR system.
        _sensor_polling_delay: Stores the delay, in microseconds, between any two consecutive sensor readout polls. This
            delay is the same for most sensor modules.
        _previous_volume: Tracks the volume of water dispensed during previous deliver_reward() calls.
        _previous_tone_duration: Tracks the auditory tone duration during previous deliver_reward() or simulate_reward()
            calls.
        _lick_monitoring: Tracks the current lick monitoring state.
        _encoder_monitoring: Tracks the current encoder monitoring state.
        _delay_timer: Stores a millisecond-precise timer used by certain sequential command methods.
        valve: The interface that controls the solenoid water valve that delivers water to the animal.
        _actor: The main interface for the 'Actor' Ataraxis Micro Controller (AMC) device.
        lick: The interface that monitors animal's interactions with the lick sensor (detects licks).

    """

    def __init__(self, data_logger: DataLogger) -> None:
        # Initializes the start state tracker first
        self._started: bool = False

        # Retrieves the Mesoscope-VR system configuration parameters and saves them to class attribute to use them from
        # class methods.
        self._system_configuration = get_system_configuration()

        # Converts the general sensor polling delay and stores it in class attribute. Unless other duration / delay
        # parameters, this one is frequently queried by class methods, so it is beneficial to statically compute
        # it once.
        self._sensor_polling_delay: float = convert_time(  # type: ignore
            time=self._system_configuration.microcontrollers.sensor_polling_delay_ms, from_units="ms", to_units="us"
        )

        # Initializes internal tracker variables
        self._previous_left_volume: float = 0.0
        self._previous_right_volume: float = 0.0
        self._previous_left_tone_duration: float = 0.0
        self._previous_right_tone_duration: float = 0.0
        self._lick_monitoring: bool = False # Tracks both lick ports

        self._delay_timer = PrecisionTimer("ms")

        # ACTOR. Actor AMC controls the hardware that needs to be triggered by PC at irregular intervals. Most of such
        # hardware is designed to produce some form of an output: deliver water reward, engage wheel breaks, issue a
        # TTL trigger, etc.

        # Module interfaces:
        self.valve_left = ValveInterface(
            module_id=np.uint8(1),
            valve_calibration_data=self._system_configuration.microcontrollers.valve_calibration_data,  # type: ignore
            debug=False,
        )

        self.valve_right = ValveInterface(
            module_id=np.uint8(2),
            valve_calibration_data=self._system_configuration.microcontrollers.valve_calibration_data,  # type: ignore
            debug=False,
        )

        self.lick_left = LickInterface(
            module_id=np.uint8(1),
            lick_threshold=self._system_configuration.microcontrollers.lick_threshold_adc,
            debug=False,
        )

        self.lick_right = LickInterface(
            module_id=np.uint8(2),
            lick_threshold=self._system_configuration.microcontrollers.lick_threshold_adc,
            debug=False,
        )

        # Main interface:
        self._actor: MicroControllerInterface = MicroControllerInterface(
            controller_id=np.uint8(101),  # Hardcoded
            microcontroller_serial_buffer_size=8192,  # Hardcoded
            microcontroller_usb_port=self._system_configuration.microcontrollers.actor_port,
            data_logger=data_logger,
            module_interfaces=tuple(self.valve_left, self.valve_right, self.lick_left, self.lick_right),
        )

    def __del__(self) -> None:
        """Ensures that all hardware resources are released when the object is garbage-collected."""
        self.stop()

    def start(self) -> None:
        """Starts MicroController communication processes and configures all hardware modules to use the runtime
        parameters loaded from the acquisition system configuration file.

        This method sets up the necessary assets that enable MicroController-PC communication. Until this method is
        called, all other class methods will not function correctly.

        Notes:
            After calling this method, most hardware modules will be initialized to an idle state. The only exception to
            this rule is the wheel break, which initializes to the 'engaged' state. Use other class methods to
            switch individual hardware modules into the desired state.

            Since most modules initialize to an idle state, they will not be generating data. Therefore, it is safe
            to call this method before enabling the DataLogger class. However, it is strongly advised to enable the
            DataLogger as soon as possible to avoid data piling up in the buffer.
        """

        # Prevents executing this method if the MicroControllers are already running.
        if self._started:
            return

        message = "Initializing Ataraxis Micro Controller (AMC) Interfaces..."
        console.echo(message=message, level=LogLevel.INFO)

        # Starts all microcontroller interfaces
        self._actor.start()
        self._actor.unlock_controller()  # Only Actor outputs data, so no need to unlock other controllers.

        # Configures the water valve to deliver ~ 5 uL of water by default.
        tone_duration: float = convert_time(  # type: ignore
            time=self._system_configuration.microcontrollers.auditory_tone_duration_ms, from_units="ms", to_units="us"
        )
        self.valve_left.set_parameters(
            pulse_duration=np.uint32(self.valve_left.get_duration_from_volume(5.0)),  # Hardcoded for calibration purposes
            calibration_delay=np.uint32(300000),  # Hardcoded! Do not decrease unless you know what you are doing!
            calibration_count=np.uint16(self._system_configuration.microcontrollers.valve_calibration_pulse_count),
            tone_duration=np.uint32(tone_duration),
        )
        self.valve_right.set_parameters(
            pulse_duration=np.uint32(self.valve_right.get_duration_from_volume(5.0)),  # Hardcoded for calibration purposes
            calibration_delay=np.uint32(300000),  # Hardcoded! Do not decrease unless you know what you are doing!
            calibration_count=np.uint16(self._system_configuration.microcontrollers.valve_calibration_pulse_count),
            tone_duration=np.uint32(tone_duration),
        )
        # Configures the lick sensor to filter out dry touches and only report significant changes in detected voltage
        # (used as a proxy for detecting licks).
        self.lick_left.set_parameters(
            signal_threshold=np.uint16(self._system_configuration.microcontrollers.lick_signal_threshold_adc),
            delta_threshold=np.uint16(self._system_configuration.microcontrollers.lick_delta_threshold_adc),
            averaging_pool_size=np.uint8(self._system_configuration.microcontrollers.lick_averaging_pool_size),
        )
        self.lick_right.set_parameters(
            signal_threshold=np.uint16(self._system_configuration.microcontrollers.lick_signal_threshold_adc),
            delta_threshold=np.uint16(self._system_configuration.microcontrollers.lick_delta_threshold_adc),
            averaging_pool_size=np.uint8(self._system_configuration.microcontrollers.lick_averaging_pool_size),
        )

        # The setup procedure is complete.
        self._started = True

        message = "Ataraxis Micro Controller (AMC) Interfaces: Initialized."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def stop(self) -> None:
        """Stops all MicroController communication processes and releases all resources.

        This method needs to be called at the end of each runtime to release the resources reserved by the start()
        method. Until the stop() method is called, the DataLogger instance may receive data from running
        MicroControllers, so calling this method also guarantees no MicroController data will be lost if the DataLogger
        process is terminated.
        """

        # Prevents stopping an already stopped VR process.
        if not self._started:
            return

        message = "Terminating Ataraxis Micro Controller (AMC) Interfaces..."
        console.echo(message=message, level=LogLevel.INFO)

        # Resets the _started tracker
        self._started = False

        # Stops all microcontroller interfaces. This directly shuts down and resets all managed hardware modules.
        self._actor.stop()

        message = "Ataraxis Micro Controller (AMC) Interfaces: Terminated."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def enable_lick_monitoring(self) -> None:
        """Enables monitoring the state of the conductive lick sensor at ~ 1 kHZ rate.

        The lick sensor measures the voltage across the lick sensor and reports surges in voltage to the PC as a
        reliable proxy for tongue-to-sensor contact. Most lick events span at least 100 ms of time and, therefore, the
        rate of 1 kHZ is adequate for resolving all expected single-lick events.
        """
        if not self._lick_monitoring:
            self.lick_left.check_state(repetition_delay=np.uint32(self._sensor_polling_delay))
            self.lick_right.check_state(repetition_delay=np.uint32(self._sensor_polling_delay))
            self._lick_monitoring = True

    def disable_lick_monitoring(self) -> None:
        """Stops monitoring the conductive lick sensor."""
        if self._lick_monitoring:
            self.lick_left.reset_command_queue()
            self.lick_right.reset_command_queue()
            self._lick_monitoring = False

    def open_valve_left(self) -> None:
        """Opens the water reward solenoid valve.

        This method is primarily used to prime the water line with water before the first experiment or training session
        of the day.
        """
        self.valve_left.toggle(state=True)

    def close_valve_left(self) -> None:
        """Closes the left water reward solenoid valve."""
        self.valve_left.toggle(state=False)

    def open_valve_right(self) -> None:
        """Opens the right water reward solenoid valve."""
        self.valve_right.toggle(state=True)

    def close_valve_right(self) -> None:
        """Closes the right water reward solenoid valve."""
        self.valve_right.toggle(state=False)

    def deliver_reward_left(self, volume: float = 5.0, tone_duration: int = 0, ignore_parameters: bool = False) -> None:
        """Pulses the water reward solenoid valve for the duration of time necessary to deliver the provided volume of
        water.

        This method assumes that the valve has been calibrated before calling this method. It uses the calibration data
        provided at class instantiation to determine the period of time the valve should be kept open to deliver the
        requested volume of water.

        Args:
            volume: The volume of water to deliver, in microliters.
            tone_duration: The duration of the auditory tone, in milliseconds, to emit while delivering the water
                reward.
            ignore_parameters: Determines whether to ignore the volume and tone_duration arguments. Calling the method
                with this argument ensures that the delivered reward always uses the same volume and tone_duration as
                the previous reward command. Primarily, this argument is used when receiving reward commands from Unity.
        """

        # This ensures that the valve settings are only updated if volume, tone_duration, or both changed compared to
        # the previous command runtime. This ensures that the valve settings are only updated when this is necessary,
        # reducing communication overhead.
        if not ignore_parameters and (volume != self._previous_left_volume or tone_duration != self._previous_left_tone_duration):
            # Parameters are cached here to use the tone_duration before it is converted to microseconds.
            self._previous_left_volume = volume
            self._previous_left_tone_duration = tone_duration

            # Note, calibration parameters are not used by the command below, but we explicitly set them here for
            # consistency
            tone_duration: float = convert_time(time=tone_duration, from_units="ms", to_units="us")  # type: ignore
            self.valve_left.set_parameters(
                pulse_duration=self.valve_left.get_duration_from_volume(volume),
                calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons!
                calibration_count=np.uint16(self._system_configuration.microcontrollers.valve_calibration_pulse_count),
                tone_duration=np.uint32(tone_duration),
            )

        self.valve_left.send_pulse(noblock=False)

    def deliver_reward_right(self, volume: float = 5.0, tone_duration: int = 0, ignore_parameters: bool = False) -> None:
        """Pulses the water reward solenoid valve for the duration of time necessary to deliver the provided volume of
        water.

        This method assumes that the valve has been calibrated before calling this method. It uses the calibration data
        provided at class instantiation to determine the period of time the valve should be kept open to deliver the
        requested volume of water.

        Args:
            volume: The volume of water to deliver, in microliters.
            tone_duration: The duration of the auditory tone, in milliseconds, to emit while delivering the water
                reward.
            ignore_parameters: Determines whether to ignore the volume and tone_duration arguments. Calling the method
                with this argument ensures that the delivered reward always uses the same volume and tone_duration as
                the previous reward command. Primarily, this argument is used when receiving reward commands from Unity.
        """

        # This ensures that the valve settings are only updated if volume, tone_duration, or both changed compared to
        # the previous command runtime. This ensures that the valve settings are only updated when this is necessary,
        # reducing communication overhead.
        if not ignore_parameters and (volume != self._previous_right_volume or tone_duration != self._previous_right_tone_duration):
            # Parameters are cached here to use the tone_duration before it is converted to microseconds.
            self._previous_right_volume = volume
            self._previous_right_tone_duration = tone_duration

            # Note, calibration parameters are not used by the command below, but we explicitly set them here for
            # consistency
            tone_duration: float = convert_time(time=tone_duration, from_units="ms", to_units="us")  # type: ignore
            self.valve_right.set_parameters(
                pulse_duration=self.valve_right.get_duration_from_volume(volume),
                calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons!
                calibration_count=np.uint16(self._system_configuration.microcontrollers.valve_calibration_pulse_count),
                tone_duration=np.uint32(tone_duration),
            )

        self.valve_right.send_pulse(noblock=False)

    def reference_left_valve(self) -> None:
        """Runs the reference valve calibration procedure.

        Reference calibration is functionally similar to the calibrate_valve() method runtime. It is, however, optimized
        to deliver the overall volume of water recognizable for the human eye looking at the syringe holding the water
        (water 'tank' used in our system). Additionally, this uses the 5 uL volume as the reference volume, which
        matches the volume we use during experiments and training sessions.

        The reference calibration HAS to be run with the water line being primed, deaerated, and the holding ('tank')
        syringe filled exactly to the 5 mL mark. This procedure is designed to dispense 5 uL of water 200 times, which
        should overall dispense ~ 1 ml of water.
        """
        tone_duration: float = convert_time(  # type: ignore
            time=self._system_configuration.microcontrollers.auditory_tone_duration_ms, from_units="ms", to_units="us"
        )
        self.valve_left.set_parameters(
            pulse_duration=np.uint32(self.valve_left.get_duration_from_volume(target_volume=5.0)),  # Hardcoded!
            calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons!
            calibration_count=np.uint16(200),  # Hardcoded to work with the 5.0 uL volume to dispense 1 ml of water.
            tone_duration=np.uint32(tone_duration),
        )  # 5 ul x 200 times

        self.valve_left.calibrate()

    def reference_right_valve(self) -> None:
        """Runs the reference valve calibration procedure.

        Reference calibration is functionally similar to the calibrate_valve() method runtime. It is, however, optimized
        to deliver the overall volume of water recognizable for the human eye looking at the syringe holding the water
        (water 'tank' used in our system). Additionally, this uses the 5 uL volume as the reference volume, which
        matches the volume we use during experiments and training sessions.

        The reference calibration HAS to be run with the water line being primed, deaerated, and the holding ('tank')
        syringe filled exactly to the 5 mL mark. This procedure is designed to dispense 5 uL of water 200 times, which
        should overall dispense ~ 1 ml of water.
        """
        tone_duration: float = convert_time(  # type: ignore
            time=self._system_configuration.microcontrollers.auditory_tone_duration_ms, from_units="ms", to_units="us"
        )
        self.valve_right.set_parameters(
            pulse_duration=np.uint32(self.valve_right.get_duration_from_volume(target_volume=5.0)),  # Hardcoded!
            calibration_delay=np.uint32(300000),  # Hardcoded for safety reasons!
            calibration_count=np.uint16(200),  # Hardcoded to work with the 5.0 uL volume to dispense 1 ml of water.
            tone_duration=np.uint32(tone_duration),
        )  # 5 ul x 200 times

        self.valve_right.calibrate()

    def calibrate_left_valve(self, pulse_duration: int = 15) -> None:
        """Cycles solenoid valve opening and closing 500 times to determine the amount of water dispensed by the input
        pulse_duration.

        The valve is kept open for the specified number of milliseconds. Between pulses, the valve is kept closed for
        300 ms. Due to our valve design, keeping the valve closed for less than 200-300 ms generates a large pressure
        at the third (Normally Open) port, which puts unnecessary strain on the port plug and internal mechanism of the
        valve.

        Notes:
            The calibration should be run with the following durations: 15 ms, 30 ms, 45 ms, and 60 ms. During testing,
            we found that these values cover the water reward range from 2 uL to 10 uL, which is enough to cover most
            training and experiment runtimes.

            Make sure that the water line is primed, deaerated, and the holding ('tank') syringe filled exactly to the
            5 mL mark at the beginning of each calibration cycle. Depending on the calibrated pulse_duration, you may
            need to refill the syringe during the calibration runtime.

        Args:
            pulse_duration: The duration, in milliseconds, the valve is kept open at each calibration cycle
        """
        pulse_us = pulse_duration * 1000  # Converts milliseconds to microseconds
        tone_duration: float = convert_time(  # type: ignore
            time=self._system_configuration.microcontrollers.auditory_tone_duration_ms, from_units="ms", to_units="us"
        )
        self.valve_left.set_parameters(
            pulse_duration=np.uint32(pulse_us),
            calibration_delay=np.uint32(300000),
            calibration_count=np.uint16(self._system_configuration.microcontrollers.valve_calibration_pulse_count),
            tone_duration=np.uint32(tone_duration),
        )
        self.valve_left.calibrate()

    def calibrate_right_valve(self, pulse_duration: int = 15) -> None:
        """Cycles solenoid valve opening and closing 500 times to determine the amount of water dispensed by the input
        pulse_duration.

        The valve is kept open for the specified number of milliseconds. Between pulses, the valve is kept closed for
        300 ms. Due to our valve design, keeping the valve closed for less than 200-300 ms generates a large pressure
        at the third (Normally Open) port, which puts unnecessary strain on the port plug and internal mechanism of the
        valve.

        Notes:
            The calibration should be run with the following durations: 15 ms, 30 ms, 45 ms, and 60 ms. During testing,
            we found that these values cover the water reward range from 2 uL to 10 uL, which is enough to cover most
            training and experiment runtimes.

            Make sure that the water line is primed, deaerated, and the holding ('tank') syringe filled exactly to the
            5 mL mark at the beginning of each calibration cycle. Depending on the calibrated pulse_duration, you may
            need to refill the syringe during the calibration runtime.

        Args:
            pulse_duration: The duration, in milliseconds, the valve is kept open at each calibration cycle
        """
        pulse_us = pulse_duration * 1000  # Converts milliseconds to microseconds
        tone_duration: float = convert_time(  # type: ignore
            time=self._system_configuration.microcontrollers.auditory_tone_duration_ms, from_units="ms", to_units="us"
        )
        self.valve_right.set_parameters(
            pulse_duration=np.uint32(pulse_us),
            calibration_delay=np.uint32(300000),
            calibration_count=np.uint16(self._system_configuration.microcontrollers.valve_calibration_pulse_count),
            tone_duration=np.uint32(tone_duration),
        )
        self.valve_right.calibrate()

    @property
    def delivered_water_volume_left(self) -> np.float64:
        """Returns the total volume of water, in microliters, dispensed by the left valve since runtime onset."""
        return self.valve_left.delivered_volume

    def delivered_water_volume_right(self) -> np.float64:
        """Returns the total volume of water, in microliters, dispensed by the right valve since runtime onset."""
        return self.valve_right.delivered_volume

    @property
    def lick_count_left(self) -> np.uint64:
        """Returns the total number of licks recorded since runtime onset."""
        return self.lick_left.lick_count

    @property
    def lick_count_right(self) -> np.uint64:
        """Returns the total number of licks recorded since runtime onset."""
        return self.lick_right.lick_count

class VideoSystems:
    """Interfaces with all cameras managed by Ataraxis Video System (AVS) classes that acquire and save camera frames
    as .mp4 video files.

    This class interfaces with the three AVS cameras used during various runtimes to record animal behavior: the face
    camera and the two body cameras (the left camera and the right camera). The face camera is a high-grade scientific
    camera that records the animal's face and pupil. The left and right cameras are lower-end security cameras recording
    the animal's body from the left and right sides.

    Notes:
        This class is primarily intended to be used internally by the _MesoscopeExperiment and _BehaviorTraining
        classes. Do not initialize this class directly unless you know what you are doing.

        Calling the initializer does not start the underlying processes. Call the appropriate start() method to start
        acquiring and displaying face and body camera frames (there is a separate method for these two groups). Call
        the appropriate save() method to start saving the acquired frames to video files. Note that there is a single
        'global' stop() method that works for all cameras at the same time.

        The class is designed to be 'lock-in'. Once a camera is enabled, the only way to disable frame acquisition is to
        call the main stop() method. Similarly, once frame saving is started, there is no way to disable it without
        stopping the whole class. This is an intentional design decision optimized to the specific class use-pattern in
        our lab.

    Args:
        data_logger: The initialized DataLogger instance used to log the data generated by the managed cameras. For most
            runtimes, this argument is resolved by the _MesoscopeExperiment or _BehaviorTraining classes that
            initialize this class.
        output_directory: The path to the directory where to output the generated .mp4 video files. Each managed camera
            generates a separate video file saved in the provided directory. For most runtimes, this argument is
            resolved by the _MesoscopeExperiment or _BehaviorTraining classes that initialize this class.

    Attributes:
        _face_camera_started: Tracks whether the face camera frame acquisition is running.
        _body_cameras_started: Tracks whether the body cameras frame acquisition is running.
        _system_configuration: Stores the configuration parameters used by the Mesoscope-VR system.
        _face-camera: The interface that captures and saves the frames acquired by the 9MP scientific camera aimed at
            the animal's face and eye from the left side (via a hot mirror).
        _left_camera: The interface that captures and saves the frames acquired by the 1080P security camera aimed on
            the left side of the animal and the right and center VR screens.
        _right_camera: The interface that captures and saves the frames acquired by the 1080P security camera aimed on
            the right side of the animal and the left VR screen.
    """

    # noinspection PyTypeChecker
    def __init__(
        self,
        data_logger: DataLogger,
        output_directory: Path,
    ) -> None:
        # Creates the _started flags first to avoid leaks if the initialization method fails.
        self._face_camera_started: bool = False
        self._body_cameras_started: bool = False

        # Retrieves the Mesoscope-VR system configuration parameters and saves them to class attribute to use them from
        # class methods.
        self._system_configuration = get_system_configuration()

        # FACE CAMERA. This is the high-grade scientific camera aimed at the animal's face using the hot-mirror. It is
        # a 10-gigabit 9MP camera with a red long-pass filter and has to be interfaced through the GeniCam API. Since
        # the VRPC has a 4090 with 2 hardware acceleration chips, we are using the GPU to save all of our frame data.
        self._face_camera: VideoSystem = VideoSystem(
            system_id=np.uint8(51),  # Hardcoded
            data_logger=data_logger,
            output_directory=output_directory,
            harvesters_cti_path=self._system_configuration.paths.harvesters_cti_path,
        )
        # The acquisition parameters (framerate, frame dimensions, crop offsets, etc.) are set via the SVCapture64
        # software and written to non-volatile device memory. Generally, all projects in the lab should be using the
        # same parameters.
        self._face_camera.add_camera(
            save_frames=True,  # Hardcoded
            camera_index=self._system_configuration.cameras.face_camera_index,
            camera_backend=CameraBackends.HARVESTERS,  # Hardcoded
            output_frames=False,  # Hardcoded, as using queue output requires library refactoring anyway.
            display_frames=self._system_configuration.cameras.display_face_camera_frames,
            display_frame_rate=25,  # Hardcoded
        )
        self._face_camera.add_video_saver(
            hardware_encoding=True,  # Hardcoded
            video_format=VideoFormats.MP4,  # Hardcoded
            video_codec=VideoCodecs.H265,  # Hardcoded
            preset=GPUEncoderPresets.SLOW,  # Hardcoded
            input_pixel_format=InputPixelFormats.MONOCHROME,  # Hardcoded
            output_pixel_format=OutputPixelFormats.YUV444,  # Hardcoded
            quantization_parameter=self._system_configuration.cameras.face_camera_quantization_parameter,
        )

        # LEFT CAMERA. A 1080P security camera that is mounted on the left side from the mouse's perspective
        # (viewing the left side of the mouse and the right screen). This camera is interfaced with through the OpenCV
        # backend.
        self._left_camera: VideoSystem = VideoSystem(
            system_id=np.uint8(62), data_logger=data_logger, output_directory=output_directory
        )

        # DO NOT try to force the acquisition rate. If it is not 30 (default), the video will not save.
        self._left_camera.add_camera(
            save_frames=True,  # Hardcoded
            # The only difference between left and right cameras.
            camera_index=self._system_configuration.cameras.left_camera_index,
            camera_backend=CameraBackends.OPENCV,  # Hardcoded
            output_frames=False,  # Hardcoded, as using queue output requires library refactoring anyway.
            display_frames=self._system_configuration.cameras.display_body_camera_frames,
            display_frame_rate=25,  # Hardcoded
            color=False,  # Hardcoded
        )
        self._left_camera.add_video_saver(
            hardware_encoding=True,  # Hardcoded
            video_format=VideoFormats.MP4,  # Hardcoded
            video_codec=VideoCodecs.H265,  # Hardcoded
            preset=GPUEncoderPresets.FAST,  # Hardcoded
            input_pixel_format=InputPixelFormats.MONOCHROME,  # Hardcoded
            output_pixel_format=OutputPixelFormats.YUV420,  # Hardcoded
            quantization_parameter=self._system_configuration.cameras.body_camera_quantization_parameter,
        )

        # RIGHT CAMERA. Same as the left camera, but mounted on the right side from the mouse's perspective.
        self._right_camera: VideoSystem = VideoSystem(
            system_id=np.uint8(73), data_logger=data_logger, output_directory=output_directory
        )
        # Same as above, DO NOT force acquisition rate
        self._right_camera.add_camera(
            save_frames=True,  # Hardcoded
            # The only difference between left and right cameras.
            camera_index=self._system_configuration.cameras.right_camera_index,
            camera_backend=CameraBackends.OPENCV,
            output_frames=False,  # Hardcoded, as using queue output requires library refactoring anyway.
            display_frames=self._system_configuration.cameras.display_body_camera_frames,
            display_frame_rate=25,  # Hardcoded
            color=False,  # Hardcoded
        )
        self._right_camera.add_video_saver(
            hardware_encoding=True,  # Hardcoded
            video_format=VideoFormats.MP4,  # Hardcoded
            video_codec=VideoCodecs.H265,  # Hardcoded
            preset=GPUEncoderPresets.FAST,  # Hardcoded
            input_pixel_format=InputPixelFormats.MONOCHROME,  # Hardcoded
            output_pixel_format=OutputPixelFormats.YUV420,  # Hardcoded
            quantization_parameter=self._system_configuration.cameras.body_camera_quantization_parameter,
        )

    def __del__(self) -> None:
        """Ensures all hardware resources are released when the class is garbage-collected."""
        self.stop()

    def start_face_camera(self) -> None:
        """Starts face camera frame acquisition.

        This method sets up both the frame acquisition (producer) process and the frame saver (consumer) process.
        However, the consumer process will not save any frames until the save_face_camera_frames () method is called.
        """

        # Prevents executing this method if the face camera is already running
        if self._face_camera_started:
            return

        message = "Initializing face camera frame acquisition..."
        console.echo(message=message, level=LogLevel.INFO)

        # Starts frame acquisition. Note, this does NOT start frame saving.
        self._face_camera.start()
        self._face_camera_started = True

        message = "Face camera frame acquisition: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def start_body_cameras(self) -> None:
        """Starts left and right (body) camera frame acquisition.

        This method sets up both the frame acquisition (producer) process and the frame saver (consumer) process for
        both cameras. However, the consumer processes will not save any frames until the save_body_camera_frames ()
        method is called.
        """

        # Prevents executing this method if the body cameras are already running
        if self._body_cameras_started:
            return

        message = "Initializing body cameras (left and right) frame acquisition..."
        console.echo(message=message, level=LogLevel.INFO)

        # Starts frame acquisition. Note, this does NOT start frame saving.
        self._left_camera.start()
        self._right_camera.start()
        self._body_cameras_started = True

        message = "Body cameras frame acquisition: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def save_face_camera_frames(self) -> None:
        """Starts saving the frames acquired by the face camera as a video file."""

        # Starts frame saving process
        self._face_camera.start_frame_saving()

        message = "Face camera frame saving: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def save_body_camera_frames(self) -> None:
        """Starts saving the frames acquired by the left and right body cameras as a video file."""

        # Starts frame saving process
        self._left_camera.start_frame_saving()
        self._right_camera.start_frame_saving()

        message = "Body cameras frame saving: Started."
        console.echo(message=message, level=LogLevel.SUCCESS)

    def stop(self) -> None:
        """Stops saving all camera frames and terminates the managed VideoSystems.

        This method needs to be called at the end of each runtime to release the resources reserved by the start()
        methods. Until the stop() method is called, the DataLogger instance may receive data from running
        VideoSystems, so calling this method also guarantees no VideoSystem data will be lost if the DataLogger
        process is terminated. Similarly, this guarantees the integrity of the generated video files.
        """

        # Prevents executing this method if no cameras are running.
        if not self._face_camera_started and not self._body_cameras_started:
            return

        message = "Terminating Ataraxis Video System (AVS) Interfaces..."
        console.echo(message=message, level=LogLevel.INFO)

        # Instructs all cameras to stop saving frames
        self._face_camera.stop_frame_saving()
        self._left_camera.stop_frame_saving()
        self._right_camera.stop_frame_saving()

        message = "Camera frame saving: Stopped."
        console.echo(message=message, level=LogLevel.SUCCESS)

        # Stops all cameras
        self._face_camera.stop()
        self._left_camera.stop()
        self._right_camera.stop()

        # Marks all cameras as stopped
        self._face_camera_started = False
        self._body_cameras_started = False

        message = "Video Systems: Terminated."
        console.echo(message=message, level=LogLevel.SUCCESS)

    @property
    def face_camera_log_path(self) -> Path:
        """Returns the path to the compressed .npz archive that stores the data logged by the face camera during
        runtime."""
        return self._face_camera.log_path

    @property
    def left_camera_log_path(self) -> Path:
        """Returns the path to the compressed .npz archive that stores the data logged by the left body camera during
        runtime."""
        return self._left_camera.log_path

    @property
    def right_camera_log_path(self) -> Path:
        """Returns the path to the compressed .npz archive that stores the data logged by the right body camera during
        runtime."""
        return self._right_camera.log_path
