from pathlib import Path

import numpy as np
import keyboard
from ataraxis_time import PrecisionTimer
from ataraxis_video_system import (
    VideoSystem,
    VideoEncoders,
    CameraInterfaces,
    EncoderSpeedPresets,
    extract_logged_camera_timestamps,
)
from ataraxis_base_utilities import LogLevel, console
from ataraxis_data_structures import DataLogger, assemble_log_archives

# Since the VideoSystem and DataLogger classes use multiprocessing under-the-hood, the runtime must be protected by the
# __main__ guard.
if __name__ == "__main__":
    # Enables the console module to communicate the example's runtime progress via the terminal.
    console.enable()

    # Specifies the directory where to save the acquired video frames and timestamps.
    # tempdir = tempfile.TemporaryDirectory()  # Creates a temporary directory for illustration purposes
    # output_directory = Path(tempdir.name)
    output_directory = Path(
        "C:\\Users\\yapici\\Dropbox\\Research_projects\\dopamine\\mazes\\linear_track\\lickometer_test"
    ).joinpath("test_output")

    # The DataLogger is used to save frame acquisition timestamps to disk as uncompressed .npy files.
    logger = DataLogger(output_directory=output_directory, instance_name="webcam")

    # The DataLogger has to be started before it can save any log entries.
    logger.start()

    # The VideoSystem minimally requires an ID and a DataLogger instance. The ID is critical, as it is used to identify
    # the log entries generated by the VideoSystem. For VideoSystems that will be saving frames, output_directory is
    # also required

    left_camera = VideoSystem(
        system_id=np.uint8(101),
        data_logger=logger,
        output_directory=output_directory,
        camera_interface=CameraInterfaces.OPENCV,  # OpenCV interface for webcameras
        camera_index=0,  # Uses the default system webcam
        display_frame_rate=15,
        frame_rate=30,
        frame_width=640,
        frame_height=360,
        color=False,  # Acquires images in MONOCHROME mode
        video_encoder=VideoEncoders.H264,  # Uses H264 CPU video encoder.
        encoder_speed_preset=EncoderSpeedPresets.FAST,
        quantization_parameter=25,  # Increments the default qp parameter to reflect using the H264 encoder.
    )

    right_camera = VideoSystem(
        system_id=np.uint8(102),
        data_logger=logger,
        output_directory=output_directory,
        camera_interface=CameraInterfaces.OPENCV,  # OpenCV interface for webcameras
        camera_index=1,  # Uses the default system webcam
        display_frame_rate=15,  # Displays the acquired data at a rate of 30 frames per second
        frame_width=640,
        frame_height=360,
        frame_rate=30,
        color=False,  # Acquires images in MONOCHROME mode
        video_encoder=VideoEncoders.H264,  # Uses H264 CPU video encoder.
        encoder_speed_preset=EncoderSpeedPresets.FAST,
        quantization_parameter=25,  # Increments the default qp parameter to reflect using the H264 encoder.
    )

    top_camera = VideoSystem(
        system_id=np.uint8(103),
        data_logger=logger,
        output_directory=output_directory,
        camera_interface=CameraInterfaces.OPENCV,  # OpenCV interface for webcameras
        camera_index=2,  # Uses the default system webcam
        display_frame_rate=15,
        frame_width=1280,
        frame_height=720,  # Displays the acquired data at a rate of 15 frames per second
        frame_rate=30,
        color=False,  # Acquires images in MONOCHROME mode
        video_encoder=VideoEncoders.H264,
        encoder_speed_preset=EncoderSpeedPresets.MEDIUM,  # Uses H264 CPU video encoder.
        quantization_parameter=25,  # Increments the default qp parameter to reflect using the H264 encoder.
    )

    # Calling this method arms the video system and starts frame acquisition. However, the frames are not initially
    # saved to disk.
    left_camera.start()
    top_camera.start()
    right_camera.start()
    console.echo("VideoSystem: Started", level=LogLevel.SUCCESS)

    console.echo("Acquiring frames without saving...")
    timer = PrecisionTimer("ms")
    timer.delay(delay=5000, block=False)  # During this delay, camera frames are displayed to the user but are not saved

    # Begins saving frames to disk as an MP4 video file
    console.echo("Saving the acquired frames to disk...")
    left_camera.start_frame_saving()
    top_camera.start_frame_saving()
    right_camera.start_frame_saving()
    console.echo("Saving started, press 'q' to quit.")

    # timer.delay(delay=5, block=False)  # Records frames for 60 seconds, generating ~1800 frames
    while True:
        if keyboard.is_pressed("q"):
            console.echo("'q' key pressed, stopping acquisition.")
            break
        timer.delay(delay=50, block=False)  # Checks every 20 ms whether the 'q' key has been pressed

    left_camera.stop_frame_saving()
    top_camera.stop_frame_saving()
    right_camera.stop_frame_saving()

    # Frame acquisition can be started and stopped as needed, although all frames are written to the same output
    # video file.

    # Stops the VideoSystem runtime and releases all resources
    console.echo("Stopping left camera")
    left_camera.stop()
    console.echo("Stopping right camera")
    right_camera.stop()
    console.echo("Stopping top camera")
    top_camera.stop()
    console.echo("VideoSystem: Stopped", level=LogLevel.SUCCESS)

    # Stops the DataLogger and assembles all logged data into a single .npz archive file. This step is required to be
    # able to extract the timestamps for further analysis.
    logger.stop()

    console.echo("Assembling the frame timestamp log archive...")
    assemble_log_archives(remove_sources=True, log_directory=logger.output_directory, verbose=True)

    # Extracts the list of frame timestamps from the assembled log archive generated above. This returns a list of
    # timestamps. Each is given in microseconds elapsed since the UTC epoch onset.
    console.echo("Extracting frame acquisition timestamps from the assembled log archive...")
    left_timestamps = extract_logged_camera_timestamps(log_path=logger.output_directory.joinpath("101_log.npz"))
    right_timestamps = extract_logged_camera_timestamps(log_path=logger.output_directory.joinpath("102_log.npz"))
    top_timestamps = extract_logged_camera_timestamps(log_path=logger.output_directory.joinpath("103_log.npz"))

    # Computes and prints the frame rate of the camera based on the extracted frame timestamp data.
    timestamp_array1 = np.array(left_timestamps, dtype=np.uint64)
    time_diffs1 = np.diff(timestamp_array1)
    fps1 = 1 / (np.mean(time_diffs1) / 1e6)

    timestamp_array2 = np.array(right_timestamps, dtype=np.uint64)
    time_diffs2 = np.diff(timestamp_array2)
    fps2 = 1 / (np.mean(time_diffs2) / 1e6)

    timestamp_array3 = np.array(top_timestamps, dtype=np.uint64)
    time_diffs3 = np.diff(timestamp_array3)
    fps3 = 1 / (np.mean(time_diffs3) / 1e6)

    console.echo(
        message=(
            f"According to the extracted timestamps, the interfaced cameras had an acquisition frame rate of "
            f"approximately {fps1:.2f} frames / second and {fps2:.2f} frames / second and {fps3:.2f} frames / second."
        ),
        level=LogLevel.SUCCESS,
    )

    # Cleans up the temporary directory before shutting the runtime down.
    # tempdir.cleanup()
